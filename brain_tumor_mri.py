# -*- coding: utf-8 -*-
"""Brain Tumor MRI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MvjZOMTKK2oJ-N5kPfiRb3vtEh2TLIyq
"""

from google.colab import drive
drive.mount('/content/drive')

# Instalar dependências
!pip install kagglehub
!pip install tensorflow
!pip install matplotlib

# Montar o Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Configurar o diretório de destino
import os
import kagglehub
import shutil

dest_dir = '/content/drive/MyDrive/PAI5'
os.makedirs(dest_dir, exist_ok=True)

# Fazer o download do dataset
bilalakgz_brain_tumor_mri_dataset_path = kagglehub.dataset_download('bilalakgz/brain-tumor-mri-dataset')

# Mover arquivos do dataset para a pasta de destino
for item in os.listdir(bilalakgz_brain_tumor_mri_dataset_path):
    shutil.move(os.path.join(bilalakgz_brain_tumor_mri_dataset_path, item), dest_dir)

print(f"Arquivos movidos para: {dest_dir}")

print("Arquivos na pasta 'PAI5':")
print(os.listdir(dest_dir))

"""# Configuração dos caminhos do dataset"""

import os
# Configuração dos caminhos do dataset
folder_path = '/content/drive/MyDrive/PAI/brain_tumor_dataset'
train_dir = os.path.join(folder_path, 'brain_tumor_segmentation/train/images')
val_dir = os.path.join(folder_path, 'brain_tumor_segmentation/valid/images')
test_dir = os.path.join(folder_path, 'brain_tumor_segmentation/test')

# Verificar se os caminhos estão corretos
print("Caminho para treino:", train_dir)
print("Caminho para validação:", val_dir)
print("Caminho para teste:", test_dir)

"""#Treinamento"""

import os
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import cv2
from tensorflow.keras import layers, Model

# Configurar os caminhos das pastas
folder_path = '/content/drive/MyDrive/PAI/brain_tumor_dataset/brain_tumor_segmentation'
train_images_dir = os.path.join(folder_path, 'train/images')
train_labels_dir = os.path.join(folder_path, 'train/labels')
test_images_dir = os.path.join(folder_path, 'test/images')
test_labels_dir = os.path.join(folder_path, 'test/labels')
val_images_dir = os.path.join(folder_path, 'valid/images')
val_labels_dir = os.path.join(folder_path, 'valid/labels')

# Função para carregar e preprocessar os dados com arquivos .txt para máscaras
import cv2

def load_data_with_txt(image_dir, label_dir, img_height, img_width):
    images, labels = [], []
    for image_file in sorted(os.listdir(image_dir)):
        # Carregar e redimensionar imagens
        image_path = os.path.join(image_dir, image_file)
        label_path = os.path.join(label_dir, image_file.replace('.jpg', '.txt'))  # Assumindo que máscaras são .txt

        # Carregar e normalizar a imagem
        image = tf.keras.preprocessing.image.load_img(image_path, target_size=(img_height, img_width))
        image = tf.keras.preprocessing.image.img_to_array(image) / 255.0
        images.append(image)

        # Criar a máscara a partir das coordenadas do .txt
        label = np.zeros((img_height, img_width, 1), dtype=np.float32)
        with open(label_path, 'r') as file:
            for line in file:
                values = list(map(float, line.strip().split()))
                class_id, *points = values
                # Converter pontos para coordenadas da máscara
                polygon = np.array(points).reshape(-1, 2) * [img_width, img_height]
                cv2.fillPoly(label, [polygon.astype(np.int32)], 1)

        labels.append(label)

    return np.array(images), np.array(labels)


# Configurações
IMG_HEIGHT, IMG_WIDTH = 128, 128
BATCH_SIZE = 1  # Aumente o batch size conforme a capacidade da GPU

# Carregar os dados
train_images, train_labels = load_data_with_txt(train_images_dir, train_labels_dir, IMG_HEIGHT, IMG_WIDTH)
val_images, val_labels = load_data_with_txt(val_images_dir, val_labels_dir, IMG_HEIGHT, IMG_WIDTH)

# Criar um dataset tf.data com paralelismo
def preprocess_dataset(images, labels):
    dataset = tf.data.Dataset.from_tensor_slices((images, labels))
    dataset = dataset.map(lambda x, y: (tf.image.resize(x, [IMG_HEIGHT, IMG_WIDTH]), y), num_parallel_calls=tf.data.AUTOTUNE)
    dataset = dataset.shuffle(100).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

    # Adicionando visualização para debug
    for img, lbl in dataset.take(1):  # Visualizar o primeiro lote
        plt.figure(figsize=(10, 5))
        for i in range(min(5, BATCH_SIZE)):  # Exibir até 5 imagens do lote
            plt.subplot(2, 5, i+1)
            plt.imshow((img[i].numpy() * 255).astype("uint8"))
            plt.title("Imagem")
            plt.axis('off')

            plt.subplot(2, 5, i+6)
            plt.imshow(lbl[i].numpy().astype("uint8"), cmap='gray')
            plt.title("Máscara")
            plt.axis('off')

        plt.tight_layout()
        plt.show()

    return dataset

train_dataset = preprocess_dataset(train_images, train_labels)
val_dataset = preprocess_dataset(val_images, val_labels)

def upsample(filters, size):
    """Camada de transposição de convolução para upsampling."""
    return tf.keras.Sequential([
        layers.Conv2DTranspose(filters, size, strides=2, padding='same'),
        layers.BatchNormalization(),
        layers.ReLU()
    ])

base_model = tf.keras.applications.MobileNetV2(input_shape=[IMG_HEIGHT, IMG_WIDTH, 3], include_top=False)
base_model.trainable = False

layer_names = [
    'block_1_expand_relu',   # Baixa resolução
    'block_3_expand_relu',   # Média resolução
    'block_6_expand_relu',   # Alta resolução
    'block_13_expand_relu',  # Maior resolução
    'block_16_project',      # Final
]
base_model_outputs = [base_model.get_layer(name).output for name in layer_names]

down_stack = Model(inputs=base_model.input, outputs=base_model_outputs)
down_stack.trainable = False

up_stack = [
    upsample(512, 3),  # 512 filtros
    upsample(256, 3),  # 256 filtros
    upsample(128, 3),  # 128 filtros
    upsample(64, 3),   # 64 filtros
]

# Função para construir o modelo
def unet_model(output_channels):
    inputs = layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, 3])

    # Encoder
    skips = down_stack(inputs)
    x = skips[-1]
    skips = reversed(skips[:-1])

    # Decoder
    for up, skip in zip(up_stack, skips):
        x = up(x)
        x = layers.Concatenate()([x, skip])

    # Saída
    x = layers.Conv2DTranspose(output_channels, 3, strides=2, padding='same')(x)
    return Model(inputs=inputs, outputs=x)

OUTPUT_CLASSES = 1  # Binário: tumor ou não
#define_model = unet_model(OUTPUT_CLASSES)
#define_model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])

def unet_model_with_dropout(output_channels):
    inputs = layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, 3])

    skips = down_stack(inputs)
    x = skips[-1]
    skips = reversed(skips[:-1])

    for up, skip in zip(up_stack, skips):
        x = up(x)
        x = layers.Concatenate()([x, skip])
        x = layers.Dropout(0.5)(x)  # Adicionando dropout

    x = layers.Conv2DTranspose(output_channels, 3, strides=2, padding='same')(x)
    return Model(inputs=inputs, outputs=x)

define_model = unet_model_with_dropout(OUTPUT_CLASSES)
define_model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])


define_model.summary()

# Treinar o modelo
EPOCHS = 100
history = define_model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)

# Avaliar o modelo
loss, accuracy = define_model.evaluate(val_dataset)
print(f"Loss: {loss}, Accuracy: {accuracy}")

# Função para criar a máscara a partir da predição
def create_mask(pred_mask):
    # Aplicar a função sigmoid para converter logits em probabilidades entre 0 e 1
    pred_mask = tf.sigmoid(pred_mask)

    # Binarizar a máscara usando um limiar de 0.5 e atribuir -1 ao invés de 0
    pred_mask = tf.where(pred_mask > 0.5, 1, -1)

    # Retornar a primeira máscara da batch
    return pred_mask[0]

# Plotar as métricas de perda e acurácia
def plot_training_history(history):
    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']
    loss = history.history['loss']
    val_loss = history.history['val_loss']

    epochs_range = range(len(acc))

    plt.figure(figsize=(12, 6))
    plt.subplot(1, 2, 1)
    plt.plot(epochs_range, acc, label='Treinamento')
    plt.plot(epochs_range, val_acc, label='Validação')
    plt.legend(loc='lower right')
    plt.title('Acurácia')

    plt.subplot(1, 2, 2)
    plt.plot(epochs_range, loss, label='Treinamento')
    plt.plot(epochs_range, val_loss, label='Validação')
    plt.legend(loc='upper right')
    plt.title('Perda')

    plt.show()

plot_training_history(history)



# Variável para definir quantos resultados serão exibidos
num_results = 10

# Função para exibir múltiplos exemplos de imagens de entrada, máscaras verdadeiras e máscaras preditas
def display_multiple_results(dataset, model, num_results=5):
    plt.figure(figsize=(15, num_results * 5))  # Ajustar o tamanho da figura para mais resultados
    title = ["Imagem de Origem", "Máscara Real", "Máscara Predita"]

    # Iterar sobre os exemplos desejados
    for i, (image, mask) in enumerate(dataset.take(num_results)):
        pred_mask = model.predict(image)  # Fazer a predição

        for j, img in enumerate([image[0], mask[0], create_mask(pred_mask)]):
            plt.subplot(num_results, 3, i * 3 + j + 1)
            plt.title(title[j])
            plt.imshow(tf.keras.utils.array_to_img(img))
            plt.axis('off')

    plt.tight_layout()
    plt.show()

# Exibir os resultados
display_multiple_results(val_dataset, define_model, num_results=num_results)

"""# SALVAR E UTILIZAR O MODELO GERADO"""

import tensorflow as tf

model = define_model 

# Salvar o modelo no formato Keras nativo
model_save_path = '/content/drive/MyDrive/PAI/meu_modelo_treinado.keras'
model.save(model_save_path)

print(f"Modelo salvo com sucesso em: {model_save_path}")

import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import regularizers

# Caminho do modelo salvo
model_save_path = '/content/drive/MyDrive/PAI/meu_modelo_treinado.keras'

# Compilar o modelo
model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])

print(f"Modelo carregado com sucesso de: {model_save_path}")

# Função para exibir os resultados qualitativos
def display_sample_results(images, labels, predictions, num_samples=5):
    plt.figure(figsize=(15, num_samples * 5))
    for i in range(num_samples):
        plt.subplot(num_samples, 3, i * 3 + 1)
        plt.title("Imagem Original")
        plt.imshow(images[i].squeeze(), cmap='gray' if images[i].shape[-1] == 1 else None)

        plt.subplot(num_samples, 3, i * 3 + 2)
        plt.title("Máscara Real")
        plt.imshow(labels[i].squeeze(), cmap='gray')

        plt.subplot(num_samples, 3, i * 3 + 3)
        plt.title("Máscara Predita")
        plt.imshow(predictions[i].squeeze(), cmap='gray')

        # Adicionar a linha vermelha na área predita
        plt.contour(predictions[i].squeeze(), levels=[0.5], colors='red')

    plt.tight_layout()
    plt.show()


# Carregar os dados de teste
import cv2

def display_sample_results(images, labels, predictions, num_samples=5, target_height=256, target_width=256):
    plt.figure(figsize=(15, num_samples * 5))
    for i in range(num_samples):
        plt.subplot(num_samples, 3, i * 3 + 1)
        plt.title("Imagem Original")
        plt.imshow(images[i].squeeze(), cmap='gray' if images[i].shape[-1] == 1 else None)

        plt.subplot(num_samples, 3, i * 3 + 2)
        plt.title("Máscara Real")
        plt.imshow(labels[i].squeeze(), cmap='gray')

        plt.subplot(num_samples, 3, i * 3 + 3)
        plt.title("Máscara Predita")

        # Redimensionar a máscara predita para o tamanho original
        prediction_resized = cv2.resize(predictions[i].squeeze(), (target_width, target_height), interpolation=cv2.INTER_LINEAR)
        plt.imshow(prediction_resized, cmap='gray')

        # Adicionar a linha vermelha na área predita redimensionada
        plt.contour(prediction_resized, levels=[0.5], colors='red')

    plt.tight_layout()
    plt.show()


IMG_HEIGHT, IMG_WIDTH = 256, 256  # Dimensões originais
TARGET_HEIGHT, TARGET_WIDTH = 128, 128  # Dimensões que o modelo espera

# Carregar e redimensionar os dados de teste
test_images, test_labels = load_data_with_txt(test_images_dir, test_labels_dir, IMG_HEIGHT, IMG_WIDTH, TARGET_HEIGHT, TARGET_WIDTH)

# Pré-processar os dados de teste (sem embaralhar)
test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))
test_dataset = test_dataset.batch(1).prefetch(tf.data.AUTOTUNE)

# Avaliação no conjunto de teste
test_loss, test_accuracy = model.evaluate(test_dataset)
print(f"Teste - Loss: {test_loss}, Accuracy: {test_accuracy}")

# Fazer predições no conjunto de teste
predictions = model.predict(test_dataset)

# Certifique-se de que os arrays são NumPy
test_images_numpy = np.array(test_images)
test_labels_numpy = np.array(test_labels)
predictions_numpy = np.array(predictions)

# Exibir os primeiros 5 exemplos de teste
display_sample_results(test_images_numpy[:5], test_labels_numpy[:5], predictions_numpy[:5])

history = model.fit(test_dataset, validation_data=val_dataset, epochs=EPOCHS)

# Salvar o histórico de treinamento
history_dict = history.history

import matplotlib.pyplot as plt

def plot_training_history(history):
    # Plotar Perda
    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    plt.plot(history['loss'], label='Perda de Treinamento')
    plt.plot(history['val_loss'], label='Perda de Validação')
    plt.xlabel('Época')
    plt.ylabel('Perda')
    plt.legend()
    plt.title('Perda de Treinamento e Validação')

    # Plotar Precisão
    plt.subplot(1, 2, 2)
    plt.plot(history['accuracy'], label='Precisão de Treinamento')
    plt.plot(history['val_accuracy'], label='Precisão de Validação')
    plt.xlabel('Época')
    plt.ylabel('Precisão')
    plt.legend()
    plt.title('Precisão de Treinamento e Validação')

    plt.tight_layout()
    plt.show()

# Chamar a função de plotagem
plot_training_history(history_dict)

# Resultados no conjunto de teste
test_loss, test_accuracy = model.evaluate(test_dataset)
print(f"Teste - Loss: {test_loss}, Accuracy: {test_accuracy}")
